{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import json\n",
    "import torch\n",
    "import tokenization\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from transformer.model import Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kor_vocab_length': 50000,\n",
       " 'eng_vocab_length': 28998,\n",
       " 'd_model': 768,\n",
       " 'd_ff': 2048,\n",
       " 'd_k': 64,\n",
       " 'd_v': 64,\n",
       " 'num_layers': 12,\n",
       " 'num_heads': 8,\n",
       " 'start_word': '[SOS]',\n",
       " 'end_word': '[EOS]',\n",
       " 'sep_word': '[SEP]',\n",
       " 'cls_word': '[CLS]',\n",
       " 'pad_word': '[PAD]',\n",
       " 'mask_word': '[MASK]'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read configuration file\n",
    "config = json.load(open('config.json'))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'you']\n",
      "['나는', '너를', '사랑', '##한다']\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file='vocab/kor_vocab.txt', do_lower_case=False)\n",
    "tgt_tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file='vocab/eng_vocab.txt', do_lower_case=False)\n",
    "print(tgt_tokenizer.tokenize('I love you'))\n",
    "print(src_tokenizer.tokenize('나는 너를 사랑한다'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[47488, 47728,  1722,  2272, 21191,  2540, 13330, 13201,  3807,  7195,\n",
      "         47488, 47459, 47492, 27321, 22775, 21385,  9246,  4037, 47558, 47467,\n",
      "          1634, 33068,  7923, 48117, 22183, 47440,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [25413, 30745, 47471, 24155, 47774,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 1612,   213, 46686,     3,  1914,  1253, 47491,  7942,  9246, 47555,\n",
      "         15713, 10552, 47668,  1239, 26620, 38688, 47461, 11548,   151,     3,\n",
      "         47440,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "tensor([[    1,  5907, 13068,  1160,   114,  1112,   172, 25889,  4050,  1117,\n",
      "          3645,  1130,  1108,  2543,  2714,  2803,  1109,  1105,  5907,   121,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [    1,  2093,  1130,  1252,  1122,   172,  1394,  3087,   138,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [    1,  1132,  2945,  1431,  3768,  1272, 26503,  1123,  1105,  8882,\n",
      "          1107,  2122,  1142,  1123,  1105,  2046,   121,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]])\n",
      "tensor([[ 5907, 13068,  1160,   114,  1112,   172, 25889,  4050,  1117,  3645,\n",
      "          1130,  1108,  2543,  2714,  2803,  1109,  1105,  5907,   121,     2,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 2093,  1130,  1252,  1122,   172,  1394,  3087,   138,     2,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 1132,  2945,  1431,  3768,  1272, 26503,  1123,  1105,  8882,  1107,\n",
      "          2122,  1142,  1123,  1105,  2046,   121,     2,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]])\n"
     ]
    }
   ],
   "source": [
    "# 'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다. -> Bible Coloring' is a coloring application that allows you to experience beautiful stories in the Bible.\n",
    "# 씨티은행에서 일하세요? -> Do you work at a City bank?\n",
    "# 11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다. -> In Chapter 11 Jesus called Lazarus from the tomb and raised him from the dead.\n",
    "\n",
    "src_text = [\n",
    "    '\\'Bible Coloring\\'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다.',\n",
    "    '씨티은행에서 일하세요?', '11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.']\n",
    "tgt_text = [\n",
    "    'Bible Coloring\\' is a coloring application that allows you to experience beautiful stories in the Bible.',\n",
    "    'Do you work at a City bank?', 'In Chapter 11 Jesus called Lazarus from the tomb and raised him from the dead.']\n",
    "\n",
    "enc_length = 40\n",
    "tgt_length = 40\n",
    "\n",
    "enc_inputs = []\n",
    "for text in src_text:\n",
    "    tokens = src_tokenizer.tokenize(text)\n",
    "    tokens = tokens[:enc_length]\n",
    "    while len(tokens) < enc_length:\n",
    "        tokens.append(config['pad_word'])\n",
    "    enc_input = src_tokenizer.convert_tokens_to_ids(tokens)\n",
    "    enc_inputs.append(enc_input)\n",
    "\n",
    "dec_inputs, dec_outputs = [], []\n",
    "for text in tgt_text:\n",
    "    tokens = [config['start_word']]\n",
    "    tokens.extend(tgt_tokenizer.tokenize(text)[:tgt_length])\n",
    "    tokens.append(config['end_word'])\n",
    "    \n",
    "    dec_input = tokens[:-1]\n",
    "    dec_output = tokens[1:]\n",
    "\n",
    "    while len(dec_input) < tgt_length + 1:\n",
    "        dec_input.append(config['pad_word'])\n",
    "    while len(dec_output) < tgt_length + 1:\n",
    "        dec_output.append(config['pad_word'])\n",
    "\n",
    "    dec_input = tgt_tokenizer.convert_tokens_to_ids(dec_input)\n",
    "    dec_output = tgt_tokenizer.convert_tokens_to_ids(dec_output)\n",
    "\n",
    "    dec_inputs.append(dec_input)\n",
    "    dec_outputs.append(dec_output)\n",
    "\n",
    "enc_inputs_tensor = torch.as_tensor(enc_inputs, dtype=torch.long).to(device)\n",
    "dec_inputs_tensor = torch.as_tensor(dec_inputs, dtype=torch.long).to(device)\n",
    "dec_outputs_tensor = torch.as_tensor(dec_outputs, dtype=torch.long).to(device)\n",
    "\n",
    "print(enc_inputs_tensor)\n",
    "print(dec_inputs_tensor)\n",
    "print(dec_outputs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Translation(\n",
       "  (encoder): Encoder(\n",
       "    (src_emb): Embedding(50000, 768)\n",
       "    (pos_emb): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (enc_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (enc_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (enc_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (enc_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (4): EncoderLayer(\n",
       "        (enc_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (5): EncoderLayer(\n",
       "        (enc_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (6): EncoderLayer(\n",
       "        (enc_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (7): EncoderLayer(\n",
       "        (enc_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (8): EncoderLayer(\n",
       "        (enc_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (9): EncoderLayer(\n",
       "        (enc_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (10): EncoderLayer(\n",
       "        (enc_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (11): EncoderLayer(\n",
       "        (enc_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (tgt_emb): Embedding(28998, 768)\n",
       "    (pos_emb): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (dec_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dec_enc_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (dec_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dec_enc_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (dec_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dec_enc_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (dec_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dec_enc_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (dec_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dec_enc_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (dec_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dec_enc_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (dec_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dec_enc_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (dec_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dec_enc_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (dec_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dec_enc_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (dec_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dec_enc_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (dec_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dec_enc_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (dec_self_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dec_enc_attn): MultiHeadAttention(\n",
       "          (WQ): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WK): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (WV): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (l1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (l2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (relu): GELU()\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (projection): Linear(in_features=768, out_features=28998, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## configure model, optimizer, criterion\n",
    "src_pad_index = src_tokenizer.convert_tokens_to_ids([config['pad_word']])[0]\n",
    "tgt_pad_index = tgt_tokenizer.convert_tokens_to_ids([config['pad_word']])[0]\n",
    "\n",
    "transformer = Translation(\n",
    "    src_vocab_size=config['kor_vocab_length'],\n",
    "    tgt_vocab_size=config['eng_vocab_length'],\n",
    "    d_model=config['d_model'], d_ff=config['d_ff'],\n",
    "    d_k=config['d_k'], d_v=config['d_v'], n_heads=config['num_heads'], \n",
    "    n_layers=config['num_layers'], src_pad_index=src_pad_index,\n",
    "    tgt_pad_index=src_pad_index, device=device).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=5e-5)\n",
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10.684340476989746\n",
      "1 4.781883716583252\n",
      "2 4.13808012008667\n",
      "3 3.881629467010498\n",
      "4 3.9668662548065186\n",
      "5 3.563756227493286\n",
      "6 3.4208152294158936\n",
      "7 3.251389503479004\n",
      "8 3.1089510917663574\n",
      "9 2.9770383834838867\n",
      "10 2.7516939640045166\n",
      "11 2.59731125831604\n",
      "12 2.474518060684204\n",
      "13 2.3434863090515137\n",
      "14 2.214052677154541\n",
      "15 2.084935426712036\n",
      "16 1.9478518962860107\n",
      "17 1.8068989515304565\n",
      "18 1.6644397974014282\n",
      "19 1.5107325315475464\n",
      "20 1.3616572618484497\n",
      "21 1.2115370035171509\n",
      "22 1.0657541751861572\n",
      "23 0.9298340678215027\n",
      "24 0.7984044551849365\n",
      "25 0.6730465292930603\n",
      "26 0.5640426278114319\n",
      "27 0.46903476119041443\n",
      "28 0.3862289488315582\n",
      "29 0.3173833191394806\n",
      "30 0.2613379955291748\n",
      "31 0.2157454639673233\n",
      "32 0.17825143039226532\n",
      "33 0.14866113662719727\n",
      "34 0.12542033195495605\n",
      "35 0.1064818948507309\n",
      "36 0.09112660586833954\n",
      "37 0.07866105437278748\n",
      "38 0.06861013174057007\n",
      "39 0.06057153642177582\n",
      "40 0.0540066696703434\n",
      "41 0.04850960522890091\n",
      "42 0.043883852660655975\n",
      "43 0.0399770624935627\n",
      "44 0.03663059324026108\n",
      "45 0.03373740613460541\n",
      "46 0.03124690242111683\n",
      "47 0.029112955555319786\n",
      "48 0.027271529659628868\n",
      "49 0.02565658651292324\n",
      "50 0.024223482236266136\n",
      "51 0.022950485348701477\n",
      "52 0.021821506321430206\n",
      "53 0.02081962116062641\n",
      "54 0.019923135638237\n",
      "55 0.01911482773721218\n",
      "56 0.01838231086730957\n",
      "57 0.01771693490445614\n",
      "58 0.01711163856089115\n",
      "59 0.016558105126023293\n",
      "60 0.016048762947320938\n",
      "61 0.015578489750623703\n",
      "62 0.015143436379730701\n",
      "63 0.014741070568561554\n",
      "64 0.01436805073171854\n",
      "65 0.014022442512214184\n",
      "66 0.013700560666620731\n",
      "67 0.013399818912148476\n",
      "68 0.013118327595293522\n",
      "69 0.012855018489062786\n",
      "70 0.012608466669917107\n",
      "71 0.012376791797578335\n",
      "72 0.012158911675214767\n",
      "73 0.011952794156968594\n",
      "74 0.011757364496588707\n",
      "75 0.011571932584047318\n",
      "76 0.011396169662475586\n",
      "77 0.011228461749851704\n",
      "78 0.011068891733884811\n",
      "79 0.010916361585259438\n",
      "80 0.010770092718303204\n",
      "81 0.010629572905600071\n",
      "82 0.010494955815374851\n",
      "83 0.010365513153374195\n",
      "84 0.010241170413792133\n",
      "85 0.010121219791471958\n",
      "86 0.01000559888780117\n",
      "87 0.009894241578876972\n",
      "88 0.009786440059542656\n",
      "89 0.009682122617959976\n",
      "90 0.009581061080098152\n",
      "91 0.009483168832957745\n",
      "92 0.009388301521539688\n",
      "93 0.009296104311943054\n",
      "94 0.009206355549395084\n",
      "95 0.00911908783018589\n",
      "96 0.009034118615090847\n",
      "97 0.00895137432962656\n",
      "98 0.008870531804859638\n",
      "99 0.008791731670498848\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    dec_logits, enc_self_attns, dec_self_attns, dec_enc_attns = transformer(enc_inputs_tensor, dec_inputs_tensor)\n",
    "    loss = criterion(\n",
    "        dec_logits.view(-1, dec_logits.size(-1)),\n",
    "        dec_outputs_tensor.contiguous().view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(epoch, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다.\n",
      "orig_text    : 'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다.\n",
      "predict_text : [SOS] Bible Coloring ' is a coloring application that allows you to experience beautiful stories in the Bible . [EOS]\n",
      "-----------------\n",
      "씨티은행에서 일하세요?\n",
      "orig_text    : 씨티은행에서 일하세요?\n",
      "predict_text : [SOS] Do you work at a City bank ? [EOS]\n",
      "-----------------\n",
      "11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.\n",
      "orig_text    : 11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.\n",
      "predict_text : [SOS] In Chapter 11 Jesus called Lazarus from the tomb and raised him from the dead . [EOS]\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    '\\'Bible Coloring\\'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다.',\n",
    "    '씨티은행에서 일하세요?', '11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.']\n",
    "\n",
    "for test_sentence in test_sentences:\n",
    "    orig_text = test_sentence\n",
    "    print(orig_text)\n",
    "    test_sentence = src_tokenizer.tokenize(test_sentence)\n",
    "    test_sentence_ids = src_tokenizer.convert_tokens_to_ids(test_sentence)\n",
    "    enc_token = torch.as_tensor([test_sentence_ids], dtype=torch.long)\n",
    "\n",
    "    test_sentence_dec = ['[SOS]']\n",
    "    test_sentence_dec = tgt_tokenizer.convert_tokens_to_ids(test_sentence_dec)\n",
    "    eos_flag = tgt_tokenizer.convert_tokens_to_ids(['[EOS]'])\n",
    "\n",
    "    while test_sentence_dec[-1] != eos_flag[0] or len(test_sentence_dec) > 50:\n",
    "        dec_input = torch.as_tensor([test_sentence_dec], dtype=torch.long)\n",
    "        enc_token, dec_input = enc_token.to(device), dec_input.to(device)\n",
    "        with torch.no_grad():\n",
    "            dec_logits, enc_self_attns, dec_self_attns, dec_enc_attns = transformer(enc_token, dec_input)\n",
    "        predict = torch.argmax(dec_logits, axis=2)[:, -1].squeeze().detach().cpu().numpy()\n",
    "        test_sentence_dec.append(int(predict))\n",
    "\n",
    "    predict_text = ' '.join(tgt_tokenizer.convert_ids_to_tokens(test_sentence_dec))\n",
    "    predict_text = predict_text.replace(\" ##\", \"\")\n",
    "    predict_text = predict_text.replace(\"##\", \"\")\n",
    "    print(f'orig_text    : {orig_text}')\n",
    "    print(f'predict_text : {predict_text}')\n",
    "    print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}